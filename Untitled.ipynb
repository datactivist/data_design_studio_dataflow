{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f05e584e-dd3f-44b8-a8f0-d4f883aa7025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Import modules\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import openai\n",
    "import random\n",
    "\n",
    "#Setting titles\n",
    "st.title(\"Dataflow design studio\")\n",
    "st.markdown('<p style=\"font-size:25px\">Statistics are just <b style=\"color:blue\">one face</b> of reality</p>', unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "# Step 2: Connect to the ChatGPT API\n",
    "def query_chatgpt(prompt):\n",
    "    api_key = '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'\n",
    "    url = 'https://api.openai.com/v1/chat/completions'\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {api_key}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    data = {\n",
    "        'model': 'gpt-3.5-turbo',\n",
    "        'messages': [{'role': 'system', 'content': 'You are a human-data interaction designer that can explain to a five year old children some insights about dataset.'},\n",
    "                     {'role': 'user', 'content': prompt}],\n",
    "        'temperature': 0.7\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "    response_json = response.json()\n",
    "    print(response_json)\n",
    "    answer = response_json['choices'][0]['message']['content']\n",
    "    return answer\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: Prepare the prompt\n",
    "def prepare_prompt(data):\n",
    "    prompt = f\"Tell me what are the two most pertinent columns/variables to understand the dataset and explain to me why. Create one sentence (max 20 words long) for each variable and use metaphors to explain. Space the two sentences:\\n\\n{data}\"\n",
    "    return prompt\n",
    "\n",
    "# Step 4: Send the prompt to ChatGPT\n",
    "def send_prompt_to_chatgpt(prompt):\n",
    "    answer = query_chatgpt(prompt)\n",
    "    return answer\n",
    "\n",
    "# Step 5: Display the response\n",
    "def display_response(response):\n",
    "    words = response.split()  # Split the response into individual words\n",
    "    colored_response = \"\"\n",
    "\n",
    "    # Define a list of colors to assign to each word\n",
    "    colors = [\"red\", \"blue\", \"green\", \"orange\", \"purple\"]\n",
    "\n",
    "    # Iterate over each word and apply a different color\n",
    "    for i, word in enumerate(words):\n",
    "        color = colors[i % len(colors)]  # Use modulo operator to cycle through colors\n",
    "        colored_word = f'<span style=\"color: {color};\">{word}</span>'\n",
    "        colored_response += colored_word + \" \"\n",
    "\n",
    "    st.markdown(f'<div style=\"font-size: 14px; margin-bottom: 20px; font-weight: bold;\">{colored_response}</div>', unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "\n",
    "# Streamlit app code\n",
    "st.subheader('Throw your messy, queasy fabric in !')\n",
    "\n",
    "# Create three columns for the file uploaders\n",
    "col1, col2, col3 = st.columns(3)\n",
    "\n",
    "# File uploader in the first column\n",
    "with col1:\n",
    "    uploaded_file1 = st.file_uploader(\"Fabric 1b\")\n",
    "    if uploaded_file1 is not None:\n",
    "        dataframe1 = pd.read_csv(uploaded_file1)\n",
    "        first_10_rows1 = dataframe1.head(10)\n",
    "        \n",
    "        # Apply random color styling to the dataframe\n",
    "        styled_dataframe1 = first_10_rows1.style.applymap(lambda x: 'background-color: #{:06x}'.format(random.randint(0, 256**3-1)))\n",
    "        \n",
    "        prompt1 = prepare_prompt(first_10_rows1)\n",
    "        response1 = send_prompt_to_chatgpt(prompt1)\n",
    "        \n",
    "        st.write(styled_dataframe1)  # Display the styled dataframe\n",
    "        display_response(response1)\n",
    "\n",
    "# File uploader in the second column\n",
    "with col2:\n",
    "    uploaded_file2 = st.file_uploader(\"Fabric 2b\")\n",
    "    if uploaded_file2 is not None:\n",
    "        dataframe2 = pd.read_csv(uploaded_file2)\n",
    "        first_10_rows2 = dataframe2.head(10)\n",
    "        \n",
    "        # Apply random color styling to the dataframe\n",
    "        styled_dataframe2 = first_10_rows2.style.applymap(lambda x: 'background-color: #{:06x}'.format(random.randint(0, 256**3-1)))\n",
    "        \n",
    "        prompt2 = prepare_prompt(first_10_rows2)\n",
    "        response2 = send_prompt_to_chatgpt(prompt2)\n",
    "        \n",
    "        st.write(styled_dataframe2)  # Display the styled dataframe\n",
    "        display_response(response2)\n",
    "\n",
    "# File uploader in the third column\n",
    "with col3:\n",
    "    uploaded_file3 = st.file_uploader(\"Fabric 3b\")\n",
    "    if uploaded_file3 is not None:\n",
    "        dataframe3 = pd.read_csv(uploaded_file3)\n",
    "        first_10_rows3 = dataframe3.head(10)\n",
    "        \n",
    "        # Apply random color styling to the dataframe\n",
    "        styled_dataframe3 = first_10_rows3.style.applymap(lambda x: 'background-color: #{:06x}'.format(random.randint(0, 256**3-1)))\n",
    "        \n",
    "        prompt3 = prepare_prompt(first_10_rows3)\n",
    "        response3 = send_prompt_to_chatgpt(prompt3)\n",
    "        \n",
    "        st.write(styled_dataframe3)  # Display the styled dataframe\n",
    "        display_response(response3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f970b24-3d0b-4ebd-92f3-6cdab2ccdf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-7GR0p7fneJiHyAXn4aAEi1OZlH99E', 'object': 'chat.completion', 'created': 1684151439, 'model': 'gpt-3.5-turbo-0301', 'usage': {'prompt_tokens': 35, 'completion_tokens': 139, 'total_tokens': 174}, 'choices': [{'message': {'role': 'assistant', 'content': \"Hello! Do you know what a dataset is? It's a bunch of information that is collected and organized in a certain way. For example, think about all the different types of fruit you can think of. If we wanted to make a dataset about fruit, we could organize it by the color of the fruit, or by the kind of fruit it is. \\n\\nNow, let's say we wanted to learn more about how many people like different types of fruit. We could ask lots of people what their favorite fruit is, and then make a dataset with all their answers. This would help us understand which fruits are the most popular! \\n\\nDoes that make sense? Do you have any questions?\"}, 'finish_reason': 'stop', 'index': 0}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello! Do you know what a dataset is? It's a bunch of information that is collected and organized in a certain way. For example, think about all the different types of fruit you can think of. If we wanted to make a dataset about fruit, we could organize it by the color of the fruit, or by the kind of fruit it is. \\n\\nNow, let's say we wanted to learn more about how many people like different types of fruit. We could ask lots of people what their favorite fruit is, and then make a dataset with all their answers. This would help us understand which fruits are the most popular! \\n\\nDoes that make sense? Do you have any questions?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_chatgpt('Hello')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
