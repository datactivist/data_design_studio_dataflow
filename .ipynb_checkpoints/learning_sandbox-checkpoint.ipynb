{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "888eba30-543e-4382-8890-f03c9c334640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255ff15f-d2ee-46d2-a7c6-55189e1216e8",
   "metadata": {},
   "source": [
    "# 🔁 1 - Data product design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a91e006-605c-4794-b525-f31609120270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 13:59:38.115 No runtime found, using MemoryCacheStorageManager\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator(_root_container=0, _provided_cursor=None, _parent=None, _block_type=None, _form_data=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting titles\n",
    "st.title(\"My First Streamlit App\")\n",
    "st.write(\"Hello, world!\")\n",
    "\n",
    "#Fetching data \n",
    "DATE_COLUMN = 'date/time'\n",
    "DATA_URL = ('https://s3-us-west-2.amazonaws.com/'\n",
    "         'streamlit-demo-data/uber-raw-data-sep14.csv.gz')\n",
    "\n",
    "@st.cache_data\n",
    "def load_data(nrows):\n",
    "    data = pd.read_csv(DATA_URL, nrows=nrows)\n",
    "    lowercase = lambda x: str(x).lower()\n",
    "    data.rename(lowercase, axis='columns', inplace=True)\n",
    "    data[DATE_COLUMN] = pd.to_datetime(data[DATE_COLUMN])\n",
    "    return data\n",
    "\n",
    "# Create a text element and let the reader know the data is loading.\n",
    "data_load_state = st.text('Loading data...')\n",
    "# Load 10,000 rows of data into the dataframe.\n",
    "data = load_data(10000)\n",
    "# Notify the reader that the data was successfully loaded.\n",
    "data_load_state.text(\"Done! (using st.cache_data)\")\n",
    "\n",
    "\n",
    "st.subheader('Raw data')\n",
    "st.write(data)\n",
    "\n",
    "st.subheader('Number of pickups by hour')\n",
    "hist_values = np.histogram(\n",
    "    data[DATE_COLUMN].dt.hour, bins=24, range=(0,24))[0]\n",
    "st.bar_chart(hist_values)\n",
    "\n",
    "\n",
    "hour_to_filter = st.slider('hour', 0, 23, 17)  # min: 0h, max: 23h, default: 17h\n",
    "filtered_data = data[data[DATE_COLUMN].dt.hour == hour_to_filter]\n",
    "st.subheader(f'Map of all pickups at {hour_to_filter}:00')\n",
    "st.map(filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7feeee-a8d9-48ea-9b5f-e7eef40319bd",
   "metadata": {},
   "source": [
    "# 🔁2 - Data product design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e7bf201-0dc4-4937-8628-010a36e0a3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.subheader('Throw your messy, queasy fabric in !')\n",
    "\n",
    "# Create three columns for the file uploaders\n",
    "col1, col2, col3 = st.columns(3)\n",
    "\n",
    "# File uploader in the first column\n",
    "with col1:\n",
    "    uploaded_file1 = st.file_uploader(\"Fabric 1\")\n",
    "    if uploaded_file1 is not None:\n",
    "        dataframe1 = pd.read_csv(uploaded_file1)\n",
    "        st.write(dataframe1)\n",
    "\n",
    "# File uploader in the second column\n",
    "with col2:\n",
    "    uploaded_file2 = st.file_uploader(\"Fabric 2\")\n",
    "    if uploaded_file2 is not None:\n",
    "        dataframe2 = pd.read_csv(uploaded_file2)\n",
    "        st.write(dataframe2)\n",
    "\n",
    "# File uploader in the third column\n",
    "with col3:\n",
    "    uploaded_file3 = st.file_uploader(\"Fabric 3\")\n",
    "    if uploaded_file3 is not None:\n",
    "        dataframe3 = pd.read_csv(uploaded_file3)\n",
    "        st.write(dataframe3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "066adba4-a083-448e-8575-0abfb11a0c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Connect to the ChatGPT API\n",
    "def query_chatgpt(prompt):\n",
    "    load_dotenv()\n",
    "    api_key = os.getenv('API_KEY')\n",
    "    print(api_key)\n",
    "    url = 'https://api.openai.com/v1/chat/completions'\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {api_key}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    data = {\n",
    "        'prompt': prompt,\n",
    "        'max_tokens': 50,\n",
    "        'temperature': 0.7,\n",
    "        'n': 1,\n",
    "        'stop': '\\n'\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "    response_json = response.json()\n",
    "    print(response_json)\n",
    "    answer = response_json['choices'][0]['text']\n",
    "    return answer\n",
    "\n",
    "# Step 3: Prepare the prompt\n",
    "def prepare_prompt(data):\n",
    "    prompt = f\"Tell me what are the two most pertinent columns/variables to understand the dataset and explain to me why:\\n\\n{data}\"\n",
    "    return prompt\n",
    "\n",
    "# Step 4: Send the prompt to ChatGPT\n",
    "def send_prompt_to_chatgpt(prompt):\n",
    "    answer = query_chatgpt(prompt)\n",
    "    return answer\n",
    "\n",
    "# Step 5: Display the response\n",
    "def display_response(response):\n",
    "    st.write(\"ChatGPT's Response:\")\n",
    "    st.write(response)\n",
    "\n",
    "\n",
    "# Streamlit app code\n",
    "st.title(\"Dataset Analysis with ChatGPT\")\n",
    "st.subheader('Throw your messy, queasy fabric in !')\n",
    "\n",
    "# Create three columns for the file uploaders\n",
    "col1, col2, col3 = st.columns(3)\n",
    "\n",
    "# File uploader in the first column\n",
    "with col1:\n",
    "    uploaded_file1 = st.file_uploader(\"Fabric 1\")\n",
    "    if uploaded_file1 is not None:\n",
    "        df1 = pd.read_csv(uploaded_file1)\n",
    "        first_10_rows1 = df1.head(10)\n",
    "        prompt1 = prepare_prompt(first_10_rows1)\n",
    "        response1 = send_prompt_to_chatgpt(prompt1)\n",
    "        st.write(first_10_rows1)\n",
    "        display_response(response1)\n",
    "\n",
    "# File uploader in the second column\n",
    "with col2:\n",
    "    uploaded_file2 = st.file_uploader(\"Fabric 2\")\n",
    "    if uploaded_file2 is not None:\n",
    "        df2 = pd.read_csv(uploaded_file2)\n",
    "        first_10_rows2 = df2.head(10)\n",
    "        prompt2 = prepare_prompt(first_10_rows2)\n",
    "        response2 = send_prompt_to_chatgpt(prompt2)\n",
    "        st.write(first_10_rows2)\n",
    "        display_response(response2)\n",
    "\n",
    "# File uploader in the third column\n",
    "with col3:\n",
    "    uploaded_file3 = st.file_uploader(\"Fabric 3\")\n",
    "    if uploaded_file3 is not None:\n",
    "        df3 = pd.read_csv(uploaded_file3)\n",
    "        first_10_rows3 = df3.head(10)\n",
    "        prompt3 = prepare_prompt(first_10_rows3)\n",
    "        response3 = send_prompt_to_chatgpt(prompt3)\n",
    "        st.write(first_10_rows3)\n",
    "        display_response(response3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "519092ce-0503-4090-a66a-7da4a707e4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'error': {'message': '', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'choices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mquery_chatgpt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHello\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 21\u001b[0m, in \u001b[0;36mquery_chatgpt\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     19\u001b[0m response_json \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(response_json)\n\u001b[0;32m---> 21\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mresponse_json\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m answer\n",
      "\u001b[0;31mKeyError\u001b[0m: 'choices'"
     ]
    }
   ],
   "source": [
    "query_chatgpt('Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6890dc56-0eb0-4b30-a9a0-1e6fd1b70151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
